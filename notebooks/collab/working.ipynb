{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-RyciDW-RCwN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bHNPnjTjRP3g"
   },
   "outputs": [],
   "source": [
    "\n",
    "#(Hyperparameters)\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    # File Paths\n",
    "    RATINGS_PATH: str = '/content/drive/MyDrive/dataset/ratings.csv'\n",
    "    MOVIES_PATH: str = '/content/drive/MyDrive/dataset/movies_encoded.csv' # Optional\n",
    "    MODEL_SAVE_PATH: str = 'movie_recommender_model.pth'\n",
    "\n",
    "    # Model Architecture\n",
    "    EMBEDDING_DIM: int = 64  # Increased slightly for better capacity\n",
    "\n",
    "    # Training Hyperparameters\n",
    "    BATCH_SIZE: int = 2048   # Increased from 128 for better GPU throughput\n",
    "    EPOCHS: int = 10         # 20 might be overkill for this simple architecture\n",
    "    LEARNING_RATE: float = 0.01\n",
    "    WEIGHT_DECAY: float = 1e-5\n",
    "    TEST_SIZE: float = 0.2\n",
    "\n",
    "    # Hardware / System\n",
    "    DEVICE: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # Auto-detect CPU cores for data loading, clamp to 8 to avoid overhead\n",
    "    NUM_WORKERS: int = min(8, multiprocessing.cpu_count())\n",
    "    PIN_MEMORY: bool = True if torch.cuda.is_available() else False\n",
    "\n",
    "config = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TTIOiMLdRVXG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# DATASET & MODEL\n",
    "\n",
    "class MovieRatingsDataset(Dataset):\n",
    "    def __init__(self, user_ids, item_ids, ratings):\n",
    "        self.user_ids = torch.LongTensor(user_ids.values)\n",
    "        self.item_ids = torch.LongTensor(item_ids.values)\n",
    "        self.ratings = torch.FloatTensor(ratings.values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.item_ids[idx], self.ratings[idx]\n",
    "\n",
    "class MatrixFactorizationWithBias(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=50):\n",
    "        super(MatrixFactorizationWithBias, self).__init__()\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        self.global_bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        # Init weights\n",
    "        self.user_embeddings.weight.data.uniform_(0, 0.05)\n",
    "        self.item_embeddings.weight.data.uniform_(0, 0.05)\n",
    "        self.user_bias.weight.data.uniform_(-0.01, 0.01)\n",
    "        self.item_bias.weight.data.uniform_(-0.01, 0.01)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_vecs = self.user_embeddings(user_ids)\n",
    "        item_vecs = self.item_embeddings(item_ids)\n",
    "        dot_product = (user_vecs * item_vecs).sum(dim=1)\n",
    "\n",
    "        user_b = self.user_bias(user_ids).squeeze()\n",
    "        item_b = self.item_bias(item_ids).squeeze()\n",
    "\n",
    "        return dot_product + user_b + item_b + self.global_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "m_kgin3qRZtl"
   },
   "outputs": [],
   "source": [
    "\n",
    "# RECOMMENDER SYSTEM\n",
    "\n",
    "class MovieRecommender:\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.cfg = config\n",
    "        print(f\"ðŸš€ Initializing on device: {self.cfg.DEVICE}\")\n",
    "\n",
    "        # Load Data\n",
    "        print(f\"ðŸ“‚ Loading data from {self.cfg.RATINGS_PATH}...\")\n",
    "        self.ratings_df = pd.read_csv(self.cfg.RATINGS_PATH)\n",
    "\n",
    "        # Load Metadata (Optional)\n",
    "        self.movies_df = None\n",
    "        if self.cfg.MOVIES_PATH and os.path.exists(self.cfg.MOVIES_PATH):\n",
    "            self.movies_df = pd.read_csv(self.cfg.MOVIES_PATH)\n",
    "            print(f\"   âœ“ Loaded metadata for {len(self.movies_df)} movies\")\n",
    "\n",
    "        # Mappings\n",
    "        self._create_mappings()\n",
    "\n",
    "        # Model placeholders\n",
    "        self.model = None\n",
    "\n",
    "    def _create_mappings(self):\n",
    "        unique_users = sorted(self.ratings_df['userId'].unique())\n",
    "        unique_items = sorted(self.ratings_df['movieId'].unique())\n",
    "\n",
    "        self.user_to_idx = {user: idx for idx, user in enumerate(unique_users)}\n",
    "        self.idx_to_user = {idx: user for user, idx in self.user_to_idx.items()}\n",
    "\n",
    "        self.item_to_idx = {item: idx for idx, item in enumerate(unique_items)}\n",
    "        self.idx_to_item = {idx: item for item, idx in self.item_to_idx.items()}\n",
    "\n",
    "        # Map IDs in DataFrame efficiently\n",
    "        self.ratings_df['user_idx'] = self.ratings_df['userId'].map(self.user_to_idx)\n",
    "        self.ratings_df['item_idx'] = self.ratings_df['movieId'].map(self.item_to_idx)\n",
    "\n",
    "        self.num_users = len(unique_users)\n",
    "        self.num_items = len(unique_items)\n",
    "        print(f\"   âœ“ Users: {self.num_users:,} | Items: {self.num_items:,} | Ratings: {len(self.ratings_df):,}\")\n",
    "\n",
    "    def prepare_data(self):\n",
    "        train_df, test_df = train_test_split(\n",
    "            self.ratings_df, test_size=self.cfg.TEST_SIZE, random_state=42\n",
    "        )\n",
    "\n",
    "        self.mean_rating = train_df['rating'].mean()\n",
    "\n",
    "        # Datasets\n",
    "        train_dataset = MovieRatingsDataset(train_df['user_idx'], train_df['item_idx'], train_df['rating'])\n",
    "        test_dataset = MovieRatingsDataset(test_df['user_idx'], test_df['item_idx'], test_df['rating'])\n",
    "\n",
    "        # DataLoaders (Optimized with num_workers and pin_memory)\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset, batch_size=self.cfg.BATCH_SIZE, shuffle=True,\n",
    "            num_workers=self.cfg.NUM_WORKERS, pin_memory=self.cfg.PIN_MEMORY\n",
    "        )\n",
    "        self.test_loader = DataLoader(\n",
    "            test_dataset, batch_size=self.cfg.BATCH_SIZE, shuffle=False,\n",
    "            num_workers=self.cfg.NUM_WORKERS, pin_memory=self.cfg.PIN_MEMORY\n",
    "        )\n",
    "        print(f\"   âœ“ Data split & Loaders ready (Batch Size: {self.cfg.BATCH_SIZE})\")\n",
    "\n",
    "    def train(self):\n",
    "        self.model = MatrixFactorizationWithBias(\n",
    "            self.num_users, self.num_items, self.cfg.EMBEDDING_DIM\n",
    "        ).to(self.cfg.DEVICE)\n",
    "\n",
    "        self.model.global_bias.data.fill_(self.mean_rating)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.cfg.LEARNING_RATE, weight_decay=self.cfg.WEIGHT_DECAY)\n",
    "        scaler = torch.amp.GradScaler(enabled=(self.cfg.DEVICE == 'cuda')) # Mixed Precision\n",
    "\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        print(\"\\nðŸ”„ Starting Training...\")\n",
    "        for epoch in range(self.cfg.EPOCHS):\n",
    "            # Training Phase\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "            pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch+1}/{self.cfg.EPOCHS} [Train]\")\n",
    "\n",
    "            for user_ids, item_ids, ratings in pbar:\n",
    "                user_ids, item_ids, ratings = user_ids.to(self.cfg.DEVICE), item_ids.to(self.cfg.DEVICE), ratings.to(self.cfg.DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Mixed Precision Forward/Backward\n",
    "                with torch.amp.autocast(device_type=self.cfg.DEVICE if self.cfg.DEVICE != 'mps' else 'cpu', enabled=(self.cfg.DEVICE == 'cuda')):\n",
    "                    predictions = self.model(user_ids, item_ids)\n",
    "                    loss = criterion(predictions, ratings)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "            avg_train_loss = train_loss / len(self.train_loader)\n",
    "\n",
    "            # Validation Phase\n",
    "            self.model.eval()\n",
    "            test_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for user_ids, item_ids, ratings in self.test_loader:\n",
    "                    user_ids, item_ids, ratings = user_ids.to(self.cfg.DEVICE), item_ids.to(self.cfg.DEVICE), ratings.to(self.cfg.DEVICE)\n",
    "                    predictions = self.model(user_ids, item_ids)\n",
    "                    loss = criterion(predictions, ratings)\n",
    "                    test_loss += loss.item()\n",
    "\n",
    "            avg_test_loss = test_loss / len(self.test_loader)\n",
    "            rmse = np.sqrt(avg_test_loss)\n",
    "\n",
    "            print(f\"   Done. Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f} | RMSE: {rmse:.4f}\")\n",
    "\n",
    "            if avg_test_loss < best_loss:\n",
    "                best_loss = avg_test_loss\n",
    "                self.save_model()\n",
    "\n",
    "    def recommend_top_k(self, user_id, k=3):\n",
    "        \"\"\"\n",
    "        Optimized vectorized inference.\n",
    "        Calculates scores for ALL unrated items in a single GPU batch instead of a loop.\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_to_idx:\n",
    "            print(f\"âŒ User {user_id} not found.\")\n",
    "            return None\n",
    "\n",
    "        user_idx = self.user_to_idx[user_id]\n",
    "\n",
    "        # Find unrated items\n",
    "        rated_items = set(self.ratings_df[self.ratings_df['user_idx'] == user_idx]['item_idx'].values)\n",
    "        all_items = set(self.item_to_idx.values())\n",
    "        unrated_items = list(all_items - rated_items)\n",
    "\n",
    "        if not unrated_items:\n",
    "            return None\n",
    "\n",
    "        # Prepare tensors for batch prediction\n",
    "        user_tensor = torch.tensor([user_idx] * len(unrated_items), dtype=torch.long, device=self.cfg.DEVICE)\n",
    "        item_tensor = torch.tensor(unrated_items, dtype=torch.long, device=self.cfg.DEVICE)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(user_tensor, item_tensor)\n",
    "\n",
    "        # Get Top K indices\n",
    "        top_k_vals, top_k_indices = torch.topk(predictions, k)\n",
    "\n",
    "        results = []\n",
    "        for i in range(len(top_k_indices)):\n",
    "            item_idx = unrated_items[top_k_indices[i].item()]\n",
    "            original_item_id = self.idx_to_item[item_idx]\n",
    "            pred_rating = top_k_vals[i].item()\n",
    "\n",
    "            res = {'movieId': original_item_id, 'predicted_rating': pred_rating}\n",
    "\n",
    "            # Attach Metadata if available\n",
    "            if self.movies_df is not None:\n",
    "                meta = self.movies_df[self.movies_df['movieId'] == original_item_id]\n",
    "                if not meta.empty:\n",
    "                    res['title'] = meta.iloc[0].get('title', 'Unknown')\n",
    "                    res['genres'] = meta.iloc[0].get('genres', 'Unknown')\n",
    "\n",
    "            results.append(res)\n",
    "\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), self.cfg.MODEL_SAVE_PATH)\n",
    "        # print(f\"   ðŸ’¾ Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lz0GV0OxResH",
    "outputId": "dc8e9afd-ced3-4f56-b41a-b666762ead9d"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Initializing on device: cuda\n",
      "ðŸ“‚ Loading data from /content/drive/MyDrive/dataset/ratings.csv...\n",
      "   âœ“ Loaded metadata for 62423 movies\n",
      "   âœ“ Users: 162,541 | Items: 59,047 | Ratings: 25,000,095\n",
      "   âœ“ Data split & Loaders ready (Batch Size: 2048)\n",
      "\n",
      "ðŸ”„ Starting Training...\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9766/9766 [04:55<00:00, 33.06it/s, loss=0.763]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done. Train Loss: 0.7833 | Test Loss: 0.7656 | RMSE: 0.8750\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9766/9766 [04:49<00:00, 33.71it/s, loss=0.705]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done. Train Loss: 0.7633 | Test Loss: 0.7628 | RMSE: 0.8734\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9766/9766 [04:44<00:00, 34.33it/s, loss=0.837]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done. Train Loss: 0.7622 | Test Loss: 0.7629 | RMSE: 0.8735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9766/9766 [04:41<00:00, 34.69it/s, loss=0.767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done. Train Loss: 0.7621 | Test Loss: 0.7617 | RMSE: 0.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9766/9766 [04:38<00:00, 35.08it/s, loss=0.819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done. Train Loss: 0.7620 | Test Loss: 0.7620 | RMSE: 0.8730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9766/9766 [04:37<00:00, 35.18it/s, loss=0.766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done. Train Loss: 0.7621 | Test Loss: 0.7622 | RMSE: 0.8730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9766/9766 [04:37<00:00, 35.14it/s, loss=0.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done. Train Loss: 0.7621 | Test Loss: 0.7626 | RMSE: 0.8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9766/9766 [04:35<00:00, 35.51it/s, loss=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done. Train Loss: 0.7619 | Test Loss: 0.7622 | RMSE: 0.8731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9766/9766 [04:35<00:00, 35.41it/s, loss=0.741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done. Train Loss: 0.7620 | Test Loss: 0.7625 | RMSE: 0.8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9766/9766 [04:41<00:00, 34.67it/s, loss=0.789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done. Train Loss: 0.7620 | Test Loss: 0.7615 | RMSE: 0.8726\n",
      "\n",
      "ðŸŽ¬ Generating recommendations for User ID: 1\n",
      " movieId  predicted_rating   title\n",
      "     318          4.423855 Unknown\n",
      "  159817          4.407789 Unknown\n",
      "    2019          4.353211 Unknown\n",
      "     858          4.316284 Unknown\n",
      "  170705          4.306252 Unknown\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXECUTION\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize\n",
    "    recommender = MovieRecommender(config)\n",
    "\n",
    "    # Prepare & Train\n",
    "    recommender.prepare_data()\n",
    "    recommender.train()\n",
    "\n",
    "    # Demonstration: Recommendations for a sample user\n",
    "    sample_user = recommender.ratings_df['userId'].iloc[0]\n",
    "    print(f\"\\nðŸŽ¬ Generating recommendations for User ID: {sample_user}\")\n",
    "\n",
    "    recs = recommender.recommend_top_k(sample_user, k=5)\n",
    "\n",
    "    if recs is not None:\n",
    "        print(recs[['movieId', 'predicted_rating', 'title'] if 'title' in recs.columns else ['movieId', 'predicted_rating']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOvgcBRKRiqC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
